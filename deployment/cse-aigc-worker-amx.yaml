apiVersion: apps/v1
kind: Deployment
metadata:
  name: cse-aigc-model-worker-amx
  namespace: aigc-amx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cse-aigc-model-worker-amx
  template:
    metadata:
      labels:
        app: cse-aigc-model-worker-amx
    spec:
      containers:
      - name: cse-aigc-model-worker-amx
        image: gar-registry.caas.intel.com/cpio/cnagc-fastchat-k8s:latest
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - mountPath: /home/ubuntu/models/
          name: model-path
        resources:
          limits:
            cpu: "16"
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        - containerPort: 21003
          name: model
          protocol: TCP
        env:
        - name: MODEL_NAME
          #value: "vicuna-7b-v1.3"
          value: "Llama-2-7b-chat-hf-sharded-bf16"
        - name: ISA_TYPE
          value: "amx"
        - name: DEPLOY_TYPE
          value: "model"
        - name: FASTCHAT_ROOT
          value: "/home/ubuntu/fastchat"
        - name: MODEL_WORKER_SVC
          value: cse-aigc-model-worker-amx.aigc-amx.svc.cluster.local
        - name: CONTROLLER_SVC
          value: cse-aigc-controller.default.svc.cluster.local
        - name: CONTROLLER_PORT
          value: "21001"
        - name: MODEL_WORKER_PORT
          value: "21003"
        - name: OMP_NUM_THREADS
          value: "16"
        command: ["/home/ubuntu/entrypoint.sh"]
      volumes:
      - name: model-path
        hostPath:
          path: /home/smgaigc/Downloads/cloud-native-aigc-pipeline-main/models/Llama-2-7b-chat-hf-sharded-bf16
          type: Directory

---
apiVersion: v1
kind: Service
metadata:
  name: cse-aigc-model-worker-amx
  namespace: aigc-amx
  labels:
    app: cse-aigc-model-worker-amx
spec:
  selector:
    app: cse-aigc-model-worker-amx
  ports:
  - protocol: TCP
    name: model
    port: 21003
    targetPort: 21003
  - name: http
    port: 8000
    protocol: TCP
    targetPort: 8000

